# app/agents/definitions.py
# GenCode Studio - Agent Definitions (Chat signature-corrected -- now async)
# Last Updated: November 8, 2025

import json
from typing import List, Optional, Dict, Any, cast, TypedDict, Literal
from app.agents.api_client import chat_async  # <-- USE ASYNC

class ChatMessage(TypedDict):
    role: Literal["system", "user", "assistant"]
    content: str

from app.agents.prompts import MARCUS_PROMPT, DEREK_PROMPT, LUNA_PROMPT, VICTORIA_PROMPT
from app.agents.state import VIRTUAL_FILE_SYSTEM, CONTRACT_CONTENT
from app.agents.types import GeneratedFile, TestReport, MarcusPlan, QAIssue
from app.utils import parser

DEFAULT_TEMPERATURE = 0.7
DEFAULT_MAX_TOKENS = 2000

# ================================================================
# MARCUS (MAIN ORCHESTRATOR)
# ================================================================

async def run_marcus_orchestrator(
    user_prompt: str,
    chat_history: List[ChatMessage],
    max_compliance_retries: int = 3
) -> str:
    print('[Marcus] Running Orchestrator...')

    initial_context = json.dumps(
        [file_path for project_files in cast(Dict[str, Dict[str, str]], VIRTUAL_FILE_SYSTEM).values() 
         for file_path in project_files.keys()] if VIRTUAL_FILE_SYSTEM else []
    )

    final_system_prompt = MARCUS_PROMPT.replace('"[]"', initial_context)
    current_prompt = user_prompt
    error_msg = 'Unknown JSON failure.'

    for attempt in range(1, max_compliance_retries + 1):
        messages: List[ChatMessage] = []
        if final_system_prompt:
            messages.append({"role": "system", "content": final_system_prompt})
        messages.extend(chat_history)
        messages.append({"role": "user", "content": current_prompt})

        raw_output = await chat_async(
            messages,
            temperature=DEFAULT_TEMPERATURE,
            max_tokens=DEFAULT_MAX_TOKENS,
            agent="Marcus"
        )

        marcus_response = parser.parse_json(raw_output)
        if marcus_response and (marcus_response.get('tool') or marcus_response.get('thought')):
            print(f"[Marcus] SUCCESS: Valid JSON response on attempt {attempt}")
            return raw_output

        try:
            json.loads(parser.sanitize_marcus_output(raw_output))
        except Exception as e:
            error_msg = str(e)

        current_prompt = (
            f"You failed to output valid JSON on your last attempt (Attempt {attempt}).\n"
            f"CRITICAL ERROR: {error_msg}\n"
            f"INVALID OUTPUT (Truncated): {raw_output[:500]}...\n"
            "You must correct the syntax and strictly adhere to the JSON OUTPUT SCHEMA. "
            "Do not use conversational text or markdown.\n"
            "Retry your original task."
        )
        print(f"[Marcus] FAILED compliance on attempt {attempt}. Coaching with error: {error_msg}")
        chat_history.append({'role': 'assistant', 'content': raw_output})
        chat_history.append({'role': 'user', 'content': current_prompt})

    raise Exception(
        f"Marcus failed JSON compliance after {max_compliance_retries} attempts. "
        f"Last error: {error_msg}"
    )

# ================================================================
# DEREK (BACKEND TESTING SUB-AGENT)
# ================================================================

async def run_derek_backend_testing(
    all_code_files: List[GeneratedFile],
    contract_content: str,
    kenji_guidelines: Optional[str] = None
) -> Optional[TestReport]:
    print('[Derek] Running Backend Testing...')

    code_context = "\n\n".join([
        f"--- {f['path']} ---\n{f['code']}"
        for f in all_code_files
    ])

    guidelines_ref = ""
    if kenji_guidelines:
        guidelines_ref = f"\n\nKENJI QA GUIDELINES (Reference):\n{kenji_guidelines[:500]}..."

    user_prompt = f"""
You are Derek, reporting to Marcus. Perform comprehensive backend testing.

CONTRACT (contracts.md):
{contract_content}

CODEBASE:
{code_context}

{guidelines_ref}

Audit everything against contracts.md and return a single JSON TestReport.
"""

    derek_system_prompt = f"""
You are Derek, a meticulous backend testing specialist.
Use Kenji's QA guidelines to audit the backend code.

{DEREK_PROMPT}

Return ONLY valid JSON with TestReport format.
"""
    messages: List[ChatMessage] = [
        {"role": "system", "content": derek_system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    raw_output = await chat_async(
        messages,
        temperature=DEFAULT_TEMPERATURE,
        max_tokens=DEFAULT_MAX_TOKENS,
        agent="Derek"
    )

    parsed = parser.parse_json(raw_output)
    if parsed and 'passed' in parsed:
        print(f"[Derek] SUCCESS: Backend test report generated. "
              f"Passed: {parsed['passed']}, Issues: {len(parsed.get('issues', []))}")
        return parsed

    print(f"[Derek] ERROR: Failed to parse test report: {raw_output[:200]}...")
    return None

# ================================================================
# LUNA (FRONTEND E2E TESTING SUB-AGENT)
# ================================================================

async def run_luna_frontend_testing(
    frontend_url: str = "http://localhost:3000",
    backend_url: str = "http://localhost:8001"
) -> Optional[Dict[str, Any]]:
    print('[Luna] Running Frontend E2E Testing...')

    user_prompt = f"""
You are Luna, reporting to Marcus. Perform comprehensive frontend E2E testing.

FRONTEND URL: {frontend_url}
BACKEND URL: {backend_url}

Test all user workflows, API integration, and accessibility.
Return a single JSON test report.
"""

    messages: List[ChatMessage] = [
        {"role": "system", "content": LUNA_PROMPT},
        {"role": "user", "content": user_prompt}
    ]

    raw_output = await chat_async(
        messages,
        temperature=DEFAULT_TEMPERATURE,
        max_tokens=DEFAULT_MAX_TOKENS,
        agent="Luna"
    )

    parsed = parser.parse_json(raw_output)
    if parsed and 'passed' in parsed:
        print(f"[Luna] SUCCESS: Frontend test report generated. "
              f"Passed: {parsed['passed']}, Failures: {len(parsed.get('failures', []))}")
        return parsed

    print(f"[Luna] ERROR: Failed to parse test report: {raw_output[:200]}...")
    return None

# ================================================================
# VICTORIA (ARCHITECTURE PLANNING SUB-AGENT)
# ================================================================

async def run_victoria_architecture(
    user_requirements: str
) -> Optional[Dict[str, Any]]:
    print('[Victoria] Creating Architecture Plan...')

    user_prompt = f"""
You are Victoria, reporting to Marcus. Create comprehensive project architecture.

USER REQUIREMENTS:
{user_requirements}

Analyze requirements and create:
1. Complete system architecture
2. API contracts (contracts.md)
3. Database schema
4. Frontend structure
5. Backend structure

Return a single JSON with all architecture details.
"""

    messages: List[ChatMessage] = [
        {"role": "system", "content": VICTORIA_PROMPT},
        {"role": "user", "content": user_prompt}
    ]

    raw_output = await chat_async(
        messages,
        temperature=DEFAULT_TEMPERATURE,
        max_tokens=DEFAULT_MAX_TOKENS,
        agent="Victoria"
    )

    parsed = parser.parse_json(raw_output)
    if parsed and 'architecture_plan' in parsed:
        print(f"[Victoria] SUCCESS: Architecture plan created. "
              f"Contracts: {'contracts_md' in parsed}, "
              f"Schema: {'database_schema' in parsed}")
        return parsed

    print(f"[Victoria] ERROR: Failed to parse architecture: {raw_output[:200]}...")
    return None

# ================================================================
# LEGACY KENJI FUNCTION (For backward compatibility)
# ================================================================

async def run_kenji_qa(
    all_code_files: List[GeneratedFile],
    contract_content: str
) -> Optional[TestReport]:
    print('[Kenji] Redirecting to Derek (backend testing)...')
    return await run_derek_backend_testing(all_code_files, contract_content)

# ================================================================
# HELPER: Get Agent Information
# ================================================================

def get_agent_info() -> Dict[str, Dict[str, str]]:
    return {
        "Marcus": {
            "name": "Marcus",
            "role": "Main Orchestrator",
            "temperature": str(DEFAULT_TEMPERATURE),
            "workflow": "Sequential 7-step process"
        },
        "Derek": {
            "name": "Derek",
            "role": "Backend Testing Specialist",
            "temperature": str(DEFAULT_TEMPERATURE),
            "when_called": "After backend development (Step 4)"
        },
        "Luna": {
            "name": "Luna",
            "role": "Frontend E2E Testing Specialist",
            "temperature": str(DEFAULT_TEMPERATURE),
            "when_called": "After user approval (Step 6)"
        },
        "Victoria": {
            "name": "Victoria",
            "role": "Architecture Planning Specialist",
            "temperature": str(DEFAULT_TEMPERATURE),
            "when_called": "At project start (Step 1)"
        }
    }
# ================================================================