{
    "audit_metadata": {
        "audit_date": "2025-12-11T11:13:18+05:30",
        "audit_type": "Comprehensive Backend Audit",
        "scope": "Read-only analysis - NO FILES MODIFIED",
        "auditor": "Antigravity AI",
        "project": "GenCode Studio Backend"
    },
    "summary": {
        "overall_health": "YELLOW",
        "top_risks": [
            "1. Version mismatch between requirements.txt and requirements.lock - several packages have different versions which could cause dependency conflicts in production",
            "2. Blocking os.walk() calls in several files (supervisor.py, snapshots.py, frontend_integration.py) can block the async event loop for large projects",
            "3. In-memory state storage (_deployments, _running_workflows, _project_budgets) will be lost on server restart - no persistence layer for critical workflow state"
        ],
        "code_logic_health": "Generally sound with well-structured error handling, good use of async patterns, and proper validation layers. The supervision system with pre-flight validation and tiered review is robust.",
        "positive_findings": [
            "Strong path traversal protection with resolve() and validate_project_id()",
            "Good use of asyncio.Lock for race condition prevention in workflow state",
            "Comprehensive budget management with per-step policies",
            "Layered validation with pre-flight checks before expensive LLM reviews",
            "Proper deprecation warnings in legacy modules"
        ]
    },
    "findings": [
        {
            "id": "DEP-001",
            "title": "Version Mismatch Between requirements.txt and requirements.lock",
            "severity": "High",
            "location": {
                "file": "requirements.txt",
                "lines": "1-45"
            },
            "type": "Inconsistency",
            "description": "requirements.txt specifies fastapi==0.115.6 but requirements.lock has fastapi==0.122.0. Similar mismatches exist for beanie (1.27.0 vs 2.0.0), motor (3.6.0 vs 3.7.1), cryptography (44.0.0 vs 46.0.1), and others. Business Rule Expected: Lock file should contain exact versions matching pinned requirements. Actual: Multiple version mismatches could lead to dependency conflicts.",
            "trace": "pip install -r requirements.txt -> installs fastapi==0.115.6 vs pip freeze shows fastapi==0.122.0",
            "reproduction": "Compare line 2 of requirements.txt (fastapi==0.115.6) with line 58 of requirements.lock (fastapi==0.122.0)",
            "suggested_fix": "Regenerate requirements.lock using 'pip freeze > requirements.lock' after installing from requirements.txt, or update requirements.txt to match the actually deployed versions.",
            "code_snippet": "requirements.txt line 2:\nfastapi==0.115.6\n\nrequirements.lock line 58:\nfastapi==0.122.0",
            "confidence": "High"
        },
        {
            "id": "ASYNC-001",
            "title": "Blocking os.walk() in Async Context",
            "severity": "Medium",
            "location": {
                "file": "app/supervision/supervisor.py",
                "function": "_read_project_files",
                "lines": "541"
            },
            "type": "Performance",
            "description": "os.walk() is a blocking I/O call used inside async functions. While supervisor.py wraps this in asyncio.to_thread (line 566), other files still have blocking os.walk calls. Business Rule: All I/O in async handlers should be non-blocking. Actual: Blocking calls can starve other coroutines.",
            "trace": "supervised_agent_call() -> _read_project_files() -> os.walk(project_path)",
            "reproduction": "```python\n# In async handler, os.walk on large project blocks\nfor root, _, files in os.walk(large_project_path):  # Blocks event loop\n    pass\n```",
            "suggested_fix": "Wrap all os.walk() calls with asyncio.to_thread() as done in supervisor.py line 566. Files needing fix: app/tracking/snapshots.py:42, app/handlers/frontend_integration.py:108, app/agents/sub_agents.py:76",
            "code_snippet": "# app/tracking/snapshots.py line 42:\nfor root, _, filenames in os.walk(project_path):\n\n# app/handlers/frontend_integration.py line 108:\nfor root, _, files in os.walk(src_dir):",
            "confidence": "High"
        },
        {
            "id": "STATE-001",
            "title": "In-Memory Workflow State Not Persisted",
            "severity": "High",
            "location": {
                "file": "app/orchestration/state.py",
                "lines": "16-20"
            },
            "type": "Logic",
            "description": "Critical workflow state (_running_workflows, _paused_workflows, _project_intents) is stored in global dicts. Server restart loses all state. Business Rule Expected: Workflow state should survive server restarts. Actual: Running workflows become orphaned after restart. Note: Some file persistence exists for paused workflows (lines 99-112).",
            "trace": "run_workflow() -> WorkflowStateManager.try_start_workflow() -> _running_workflows[project_id] = True -> [SERVER RESTART] -> state lost",
            "reproduction": "1. Start a workflow POST /api/workspace/{id}/generate/backend\n2. Restart the server\n3. Check GET /api/agents/active - returns empty, but containers may still be running",
            "suggested_fix": "Use the existing checkpoint system (CheckpointManagerV2) or persist critical state to MongoDB using the existing Beanie setup. Alternative: Store running state in Redis.",
            "code_snippet": "# app/orchestration/state.py lines 16-20:\n_paused_workflows: Dict[str, Dict[str, Any]] = {}\n_project_intents: Dict[str, Dict[str, Any]] = {}\n_original_requests: Dict[str, str] = {}\n_running_workflows: Dict[str, bool] = {}\n_active_managers: Dict[str, Any] = {}",
            "confidence": "High"
        },
        {
            "id": "STATE-002",
            "title": "Deployment State Not Persisted to Database",
            "severity": "Medium",
            "location": {
                "file": "app/api/deployment.py",
                "lines": "36-37"
            },
            "type": "Logic",
            "description": "Deployment configurations are stored in _deployments dict (line 37). Comment on line 36 says 'would be in DB in production'. Business Rule Expected: Deployment state persists across restarts. Actual: All deployment configs lost on restart.",
            "trace": "POST /api/deployment/initialize -> _deployments[projectId] = {...} -> [SERVER RESTART] -> state lost",
            "reproduction": "curl -X POST /api/deployment/initialize -d '{\"projectId\": \"test\"}'\nRestart server\ncurl GET /api/deployment/status/test  # Returns not_deployed",
            "suggested_fix": "Create a Deployment Beanie model similar to Project model and persist to MongoDB. The infrastructure already exists in app/db/__init__.py.",
            "code_snippet": "# app/api/deployment.py lines 36-37:\n# In-memory storage for deployment state (would be in DB in production)\n_deployments: Dict[str, dict] = {}",
            "confidence": "High"
        },
        {
            "id": "SEC-001",
            "title": "Encryption Key Error-Before-Check Pattern",
            "severity": "Low",
            "location": {
                "file": "app/lib/secrets.py",
                "function": "encrypt_secret",
                "lines": "26-27"
            },
            "type": "Security",
            "description": "encrypt_secret checks ENCRYPTION_KEY env var but uses key_base64 parameter. If ENCRYPTION_KEY is empty but key_base64 is provided, encryption would fail with misleading error. Business Rule: Should validate the actual key being used.",
            "trace": "encrypt_secret(plaintext, key_base64) -> checks os.getenv('ENCRYPTION_KEY') -> ignores key_base64 validity",
            "reproduction": "encrypt_secret('secret', 'valid_key') when ENCRYPTION_KEY env not set -> raises 'ENCRYPTION_KEY not configured' even though a key was provided",
            "suggested_fix": "Change check to validate key_base64 parameter instead of environment variable, or document that ENCRYPTION_KEY must match key_base64 parameter.",
            "code_snippet": "# app/lib/secrets.py lines 26-27:\ndef encrypt_secret(plaintext: str, key_base64: str) -> EncryptedSecret:\n    if not os.getenv(\"ENCRYPTION_KEY\"):\n        raise ValueError(\"ENCRYPTION_KEY environment variable not configured\")",
            "confidence": "Medium"
        },
        {
            "id": "LOGIC-001",
            "title": "Budget Manager Uses Threading Lock in Async Context",
            "severity": "Low",
            "location": {
                "file": "app/orchestration/budget_manager.py",
                "lines": "159, 353"
            },
            "type": "Performance",
            "description": "BudgetManager uses threading.Lock() which is a blocking lock. In an async application, this can cause deadlocks or block the event loop if held during an await. Business Rule: Async code should use asyncio.Lock. Actual: Uses threading.Lock.",
            "trace": "budget.register_usage() -> with self._lock: -> blocks event loop if another coroutine holds lock",
            "reproduction": "Two concurrent register_usage calls from different coroutines could block each other synchronously",
            "suggested_fix": "Replace threading.Lock with asyncio.Lock and change 'with self._lock:' to 'async with self._lock:'. Alternatively, since operations are quick (no await inside lock), this is low risk.",
            "code_snippet": "# app/orchestration/budget_manager.py line 159:\nself._lock = threading.Lock()\n\n# line 175:\nwith self._lock:\n    self._reset_run_state()",
            "confidence": "Medium"
        },
        {
            "id": "VALID-001",
            "title": "Project Status Transitions Lack Formal Guards",
            "severity": "Medium",
            "location": {
                "file": "app/models/project.py",
                "lines": "13"
            },
            "type": "Logic",
            "description": "Project.status has comment indicating allowed values (created, analyzing, building, completed, failed) but no validation. Status can be set to any string. Business Rule Expected: Status should only transition through valid states. Actual: No state machine enforcement.",
            "trace": "Any code -> project.status = 'invalid_state' -> saves without validation",
            "reproduction": "project.status = 'banana'  # Saves successfully",
            "suggested_fix": "Use Pydantic's Literal type or an Enum: status: Literal['created', 'analyzing', 'building', 'completed', 'failed'] = 'created'",
            "code_snippet": "# app/models/project.py line 13:\nstatus: str = \"created\"  # created, analyzing, building, completed, failed",
            "confidence": "High"
        },
        {
            "id": "ATOMIC-001",
            "title": "Non-Atomic File Operations in Workflow Scaffolding",
            "severity": "Medium",
            "location": {
                "file": "app/workflow/engine.py",
                "function": "run_workflow",
                "lines": "282-352"
            },
            "type": "Logic",
            "description": "Scaffolding copies multiple template directories. If any copy fails mid-process, the project is left in an inconsistent state with partial files. Business Rule: Template copying should be atomic. Actual: Each copy is independent.",
            "trace": "run_workflow() -> shutil.copytree(backend_seed) succeeds -> shutil.copytree(frontend_seed) fails -> project has backend but no frontend",
            "reproduction": "Set frontend_seed to a non-existent path with backend_seed valid -> partial scaffold",
            "suggested_fix": "Wrap scaffolding in try/except and implement rollback (delete project_path) on failure. Or use a temp directory and move atomically after all copies succeed.",
            "code_snippet": "# app/workflow/engine.py lines 295-297:\nif backend_seed.exists():\n    shutil.copytree(backend_seed, backend_dest, dirs_exist_ok=True)\n    log(\"WORKFLOW\", \"✅ Seeded Backend Infrastructure...\")",
            "confidence": "High"
        },
        {
            "id": "EDGE-001",
            "title": "Empty File List Handling Could Return Success",
            "severity": "Low",
            "location": {
                "file": "app/supervision/supervisor.py",
                "lines": "651-658"
            },
            "type": "Logic",
            "description": "When agent produces no files, code continues to retry loop properly now (fixed from previous audit), but there's still a path where files=[] with parse_warning could slip through validation. FIX #6 comment indicates this was addressed.",
            "trace": "supervised_agent_call() -> tool_result has files=[] -> properly handled with continue",
            "reproduction": "Agent returns {\"files\": [], \"parse_warning\": \"...\"} -> handled by retry loop",
            "suggested_fix": "Current implementation is correct. The retry loop handles empty files properly.",
            "code_snippet": "# app/supervision/supervisor.py lines 651-658:\nif \"files\" not in parsed or not parsed[\"files\"]:\n    log(\"SUPERVISION\", f\"⚠️ {agent_name} produced no files - NOT approved\", project_id=project_id)\n    if attempt >= max_retries:\n        return {\"output\": parsed, \"approved\": False, \"attempt\": attempt, \"error\": \"No files generated\"}\n    continue",
            "confidence": "High"
        },
        {
            "id": "CONFIG-001",
            "title": "Default Model Mismatch Between config.py and .env.example",
            "severity": "Low",
            "location": {
                "file": "app/core/config.py",
                "lines": "18"
            },
            "type": "Inconsistency",
            "description": "config.py defaults to 'gemini-2.0-flash-exp' but .env.example shows 'gemini-2.0-flash'. Business Rule: Defaults should be consistent. Actual: Slight inconsistency in model naming.",
            "trace": "User doesn't set DEFAULT_LLM_MODEL -> config.py uses 'gemini-2.0-flash-exp' vs .env.example suggests 'gemini-2.0-flash'",
            "reproduction": "Compare config.py:18 default_model with .env.example:36 DEFAULT_LLM_MODEL",
            "suggested_fix": "Update .env.example line 36 to match config.py default, or update config.py to use 'gemini-2.0-flash' for consistency.",
            "code_snippet": "# app/core/config.py line 18:\ndefault_model: str = field(default_factory=lambda: os.getenv(\"DEFAULT_LLM_MODEL\", \"gemini-2.0-flash-exp\"))\n\n# .env.example line 36:\nDEFAULT_LLM_MODEL=gemini-2.0-flash",
            "confidence": "High"
        },
        {
            "id": "PERF-001",
            "title": "Potential N+1 Query Pattern in Project Listing",
            "severity": "Low",
            "location": {
                "file": "app/api/projects.py",
                "function": "list_projects",
                "lines": "136-171"
            },
            "type": "Performance",
            "description": "list_projects iterates through all workspace directories and reads project.json for each. For many projects, this becomes slow. Complexity: O(n) file reads + O(n log n) sorting. Business Rule: List operations should be efficient. Actual: Linear file operations.",
            "trace": "GET /api/projects -> iterdir() -> for p in sorted_paths: -> read project.json for EACH",
            "reproduction": "Create 100+ projects -> GET /api/projects becomes slow",
            "suggested_fix": "Consider caching project metadata in MongoDB (already have Project model) or implement pagination with ?skip=0&limit=20. Could also add an index endpoint that returns only IDs/names.",
            "code_snippet": "# app/api/projects.py lines 142-155:\nfor p in sorted_paths:\n    metadata_path = p / \"project.json\"\n    if metadata_path.exists():\n        try:\n            with open(metadata_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)",
            "confidence": "Medium"
        },
        {
            "id": "TEST-001",
            "title": "Test Coverage Limited to Smoke Tests",
            "severity": "Medium",
            "location": {
                "file": "tests/",
                "lines": "N/A"
            },
            "type": "Test",
            "description": "Tests are primarily smoke tests checking if modules load without crashing. No unit tests for business logic, no integration tests for API endpoints, no mocked database tests. Business Rule: Critical paths should have test coverage. Actual: Only 3 test files with basic checks.",
            "trace": "pytest tests/ -> runs ~12 tests, all smoke/sanity checks",
            "reproduction": "Run pytest --cov=app tests/ to see coverage report",
            "suggested_fix": "Add unit tests for: path validation, workflow state transitions, budget calculations, parser edge cases. Add API integration tests for project CRUD, workflow start/stop.",
            "code_snippet": "# Current tests are smoke tests:\n# tests/test_health.py - checks /healthz and /api/health\n# tests/test_smoke.py - checks modules load without crash",
            "confidence": "High"
        },
        {
            "id": "DB-001",
            "title": "Database Name Parsing Could Fail on Complex URIs",
            "severity": "Low",
            "location": {
                "file": "app/db/__init__.py",
                "function": "connect_db",
                "lines": "28"
            },
            "type": "Logic",
            "description": "Database name extraction uses simple split logic that may fail for URIs with query parameters or replica sets. Business Rule: Should reliably extract DB name from any valid MongoDB URI. Actual: Only handles simple URIs.",
            "trace": "connect_db() -> mongo_url='mongodb://host/db?authSource=admin' -> split('@')[-1] = 'host/db?authSource=admin' -> '/' in -> True -> get_default_database() may work but is ambiguous",
            "reproduction": "Set MONGODB_URL='mongodb+srv://user:pass@cluster.mongodb.net/mydb?retryWrites=true' -> parsing may be incorrect",
            "suggested_fix": "Use pymongo's parse_uri function: from pymongo import uri_parser; parsed = uri_parser.parse_uri(mongo_url); db_name = parsed.get('database')",
            "code_snippet": "# app/db/__init__.py line 28:\n_db = _client.get_default_database() if \"/\" in mongo_url.split(\"@\")[-1] else _client.gencode",
            "confidence": "Medium"
        },
        {
            "id": "SEC-002",
            "title": "CORS Wildcard Warning Not Enforced in Production",
            "severity": "Low",
            "location": {
                "file": "app/main.py",
                "lines": "91-95"
            },
            "type": "Security",
            "description": "CORS allows '*' by default and only prints a warning if not in debug mode. In production, this should be blocked or require explicit confirmation. Business Rule: Production should have restricted CORS. Actual: Warning only, no enforcement.",
            "trace": "app startup -> cors_origins = ['*'] -> settings.debug = False -> prints warning but allows *",
            "reproduction": "Deploy without setting CORS_ORIGINS -> all origins allowed",
            "suggested_fix": "In production (not debug), default to localhost-only or throw an error requiring CORS_ORIGINS to be explicitly set.",
            "code_snippet": "# app/main.py lines 91-95:\ncors_origins_str = os.getenv(\"CORS_ORIGINS\", \"*\")\ncors_origins = cors_origins_str.split(\",\") if cors_origins_str != \"*\" else [\"*\"]\n\nif cors_origins == [\"*\"] and not settings.debug:\n    print(\"⚠️ [CORS] Warning: Using allow_origins=['*'] - consider setting CORS_ORIGINS\")",
            "confidence": "Medium"
        }
    ],
    "correctness_statements": {
        "workflow_state_management": {
            "verdict": "CORRECT with caveats",
            "proof": "WorkflowStateManager.try_start_workflow() uses asyncio.Lock to atomically check and set running state (lines 51-70). This prevents race conditions where two requests could both think they started the workflow. The lock is held during the check-and-set operation, ensuring mutual exclusion.",
            "caveat": "State is in-memory only. Server restart loses state. Partially mitigated by file persistence for paused workflows."
        },
        "path_traversal_protection": {
            "verdict": "CORRECT",
            "proof": "get_safe_project_path() in app/api/workspace.py (lines 37-56) validates project_id with regex, then resolves paths and checks they remain within workspaces_dir. resolve() handles symlink attacks. Pattern: ^[a-zA-Z0-9_-]{1,100}$ prevents all path injection."
        },
        "budget_management": {
            "verdict": "CORRECT",
            "proof": "BudgetManager tracks usage per step with configurable policies (lines 37-145). allowed_attempts_for_step() calculates remaining budget and returns 0 if exhausted (lines 218-255). Skippable steps are handled gracefully. Cost estimation uses conservative multipliers (2x-4x) to prevent over-budget runs."
        },
        "pre_flight_validation": {
            "verdict": "CORRECT",
            "proof": "preflight_check() in app/validation/syntax_validator.py validates all files before expensive LLM review. AST parsing catches Python syntax errors, bracket counting catches JS issues. Auto-fixes are applied (import formatting, backslash removal). Only valid files proceed to Marcus review."
        },
        "websocket_connection_management": {
            "verdict": "CORRECT",
            "proof": "ConnectionManager uses asyncio.Lock for thread-safe connect/disconnect (lines 19-35 in lib/websocket.py). send_to_project takes a snapshot of connections under lock before iterating, preventing modification during send."
        }
    },
    "state_machines": {
        "project_status": {
            "allowed_transitions": [
                "created -> analyzing",
                "analyzing -> building",
                "building -> completed",
                "building -> failed",
                "analyzing -> failed",
                "any -> failed (on error)"
            ],
            "guards": "MISSING - status is a plain string with no validation",
            "recommendation": "Add Pydantic Literal or Enum validation"
        },
        "workflow_state": {
            "allowed_transitions": [
                "not_started -> running (try_start_workflow returns True)",
                "running -> paused (pause_workflow called)",
                "paused -> running (resume_workflow called)",
                "running -> stopped (stop_workflow called)",
                "paused -> stopped (cleanup called)"
            ],
            "guards": "PRESENT - try_start_workflow uses Lock for atomic check-and-set",
            "recommendation": "Add file persistence for running state to survive restarts"
        }
    },
    "complexity_analysis": {
        "list_projects": {
            "complexity": "O(n log n) + O(n) file reads",
            "where_n": "number of projects in workspaces directory",
            "mitigation": "Consider pagination or MongoDB-backed listing"
        },
        "normalize_llm_output": {
            "complexity": "O(n) where n = length of LLM output",
            "notes": "Multiple regex passes, but bounded by _MAX_PARSING_DEPTH (3) to prevent infinite recursion"
        },
        "supervised_agent_call": {
            "complexity": "O(r * f) where r = retries, f = files per attempt",
            "notes": "Each retry involves full LLM call + Marcus review. Budget limits prevent unbounded retries."
        }
    },
    "checks_performed": [
        {
            "type": "static_analysis",
            "tool": "grep_search",
            "status": "completed",
            "notes": "Searched for sensitive patterns (password, secret, eval, exec)"
        },
        {
            "type": "static_analysis",
            "tool": "grep_search os.walk",
            "status": "completed",
            "notes": "Found 4 blocking os.walk calls"
        },
        {
            "type": "static_analysis",
            "tool": "grep_search subprocess",
            "status": "completed",
            "notes": "No blocking subprocess.run found - all async"
        },
        {
            "type": "static_analysis",
            "tool": "grep_search bare_except",
            "status": "completed",
            "notes": "No bare 'except:' clauses found"
        },
        {
            "type": "dependency_audit",
            "tool": "manual_comparison",
            "status": "completed",
            "notes": "Compared requirements.txt vs requirements.lock"
        },
        {
            "type": "code_review",
            "tool": "view_file",
            "status": "completed",
            "notes": "Reviewed all API routers, models, handlers, orchestration, workflow engine"
        },
        {
            "type": "test_review",
            "tool": "view_file",
            "status": "completed",
            "notes": "Reviewed conftest.py and test files"
        },
        {
            "type": "security_review",
            "tool": "view_file + grep",
            "status": "completed",
            "notes": "Reviewed path traversal protections, secrets handling, CORS"
        }
    ],
    "files_examined": {
        "total_files": 135,
        "config_files": [
            "Backend/.env.example",
            "Backend/requirements.txt",
            "Backend/requirements.lock",
            "Backend/pytest.ini"
        ],
        "app_core": [
            "app/__init__.py",
            "app/main.py",
            "app/config.py",
            "app/core/__init__.py",
            "app/core/config.py",
            "app/core/constants.py",
            "app/core/exceptions.py",
            "app/core/integration.py",
            "app/core/logging.py",
            "app/core/types.py"
        ],
        "app_db": [
            "app/db/__init__.py"
        ],
        "app_models": [
            "app/models/__init__.py",
            "app/models/project.py",
            "app/models/snapshot.py",
            "app/models/workflow.py"
        ],
        "app_api": [
            "app/api/__init__.py",
            "app/api/agents.py",
            "app/api/deployment.py",
            "app/api/health.py",
            "app/api/projects.py",
            "app/api/providers.py",
            "app/api/sandbox.py",
            "app/api/tracking.py",
            "app/api/workspace.py"
        ],
        "app_handlers": [
            "app/handlers/__init__.py",
            "app/handlers/analysis.py",
            "app/handlers/architecture.py",
            "app/handlers/backend.py",
            "app/handlers/base.py",
            "app/handlers/contracts.py",
            "app/handlers/frontend_integration.py",
            "app/handlers/frontend_mock.py",
            "app/handlers/preview.py",
            "app/handlers/refine.py",
            "app/handlers/screenshot_verify.py",
            "app/handlers/testing_backend.py",
            "app/handlers/testing_frontend.py"
        ],
        "app_orchestration": [
            "app/orchestration/__init__.py",
            "app/orchestration/artifact_contracts.py",
            "app/orchestration/attention_router.py",
            "app/orchestration/budget_manager.py",
            "app/orchestration/checkpoint.py",
            "app/orchestration/context.py",
            "app/orchestration/critical_step_barriers.py",
            "app/orchestration/error_router.py",
            "app/orchestration/fallback_api_agent.py",
            "app/orchestration/fallback_router_agent.py",
            "app/orchestration/fast_orchestrator.py",
            "app/orchestration/file_persistence.py",
            "app/orchestration/healing_pipeline.py",
            "app/orchestration/llm_output_integrity.py",
            "app/orchestration/prompt_adapter.py",
            "app/orchestration/self_healing_manager.py",
            "app/orchestration/state.py",
            "app/orchestration/step_contracts.py",
            "app/orchestration/structural_compiler.py",
            "app/orchestration/task_graph.py",
            "app/orchestration/token_policy.py",
            "app/orchestration/utils.py"
        ],
        "app_llm": [
            "app/llm/__init__.py",
            "app/llm/adapter.py",
            "app/llm/prompt_management.py",
            "app/llm/prompts/__init__.py",
            "app/llm/prompts/derek.py",
            "app/llm/prompts/luna.py",
            "app/llm/prompts/marcus.py",
            "app/llm/prompts/victoria.py",
            "app/llm/providers/__init__.py",
            "app/llm/providers/anthropic.py",
            "app/llm/providers/gemini.py",
            "app/llm/providers/ollama.py",
            "app/llm/providers/openai.py"
        ],
        "app_sandbox": [
            "app/sandbox/__init__.py",
            "app/sandbox/health_monitor.py",
            "app/sandbox/log_streamer.py",
            "app/sandbox/sandbox_config.py",
            "app/sandbox/sandbox_manager.py"
        ],
        "app_supervision": [
            "app/supervision/__init__.py",
            "app/supervision/supervisor.py"
        ],
        "app_tools": [
            "app/tools/__init__.py",
            "app/tools/implementations.py",
            "app/tools/registry.py"
        ],
        "app_lib": [
            "app/lib/__init__.py",
            "app/lib/file_system.py",
            "app/lib/monitoring.py",
            "app/lib/patch_engine.py",
            "app/lib/patch_writer.py",
            "app/lib/secrets.py",
            "app/lib/websocket.py"
        ],
        "app_persistence": [
            "app/persistence/__init__.py",
            "app/persistence/validator.py",
            "app/persistence/writer.py"
        ],
        "app_utils": [
            "app/utils/__init__.py",
            "app/utils/entity_discovery.py",
            "app/utils/parser.py",
            "app/utils/ui_beautifier.py"
        ],
        "app_validation": [
            "app/validation/__init__.py",
            "app/validation/syntax_validator.py"
        ],
        "app_testing": [
            "app/testing/__init__.py",
            "app/testing/parallel.py",
            "app/testing/self_healing.py"
        ],
        "app_tracking": [
            "app/tracking/__init__.py",
            "app/tracking/memory.py",
            "app/tracking/snapshots.py"
        ],
        "app_agents": [
            "app/agents/__init__.py",
            "app/agents/sub_agents.py"
        ],
        "app_learning": [
            "app/learning/__init__.py",
            "app/learning/pattern_store.py"
        ],
        "app_workflow": [
            "app/workflow/__init__.py",
            "app/workflow/engine.py"
        ],
        "tests": [
            "tests/__init__.py",
            "tests/conftest.py",
            "tests/test_health.py",
            "tests/test_smoke.py"
        ]
    },
    "next_steps": [
        {
            "priority": 1,
            "action": "Fix version mismatches in requirements.txt/lock",
            "effort": "Quick win (15 min)",
            "impact": "Prevents dependency conflicts in production"
        },
        {
            "priority": 2,
            "action": "Add asyncio.to_thread() to remaining os.walk() calls",
            "effort": "Quick win (30 min)",
            "impact": "Prevents event loop blocking on large projects",
            "files": [
                "app/tracking/snapshots.py:42",
                "app/handlers/frontend_integration.py:108",
                "app/agents/sub_agents.py:76"
            ]
        },
        {
            "priority": 3,
            "action": "Add status enum validation to Project model",
            "effort": "Quick win (15 min)",
            "impact": "Prevents invalid status values"
        },
        {
            "priority": 4,
            "action": "Persist deployment state to MongoDB",
            "effort": "Medium (1-2 hours)",
            "impact": "Deployment configs survive restarts"
        },
        {
            "priority": 5,
            "action": "Add unit tests for critical business logic",
            "effort": "Medium-High (4-8 hours)",
            "impact": "Catches regressions, improves confidence"
        },
        {
            "priority": 6,
            "action": "Implement workflow state persistence to survive restarts",
            "effort": "High (4-8 hours)",
            "impact": "Running workflows survive server restarts"
        }
    ],
    "needs_environment": [
        {
            "item": "pytest execution",
            "requires": "Python environment with dependencies installed, MongoDB running",
            "command": "cd Backend && pytest tests/ -v --cov=app"
        },
        {
            "item": "Static type checking",
            "requires": "mypy installed",
            "command": "cd Backend && mypy app/ --ignore-missing-imports"
        },
        {
            "item": "Dependency vulnerability scan",
            "requires": "pip-audit or safety installed",
            "command": "cd Backend && pip-audit -r requirements.txt"
        },
        {
            "item": "Vault integration verification",
            "requires": "VAULT_URL and VAULT_TOKEN environment variables",
            "notes": "app/lib/secrets.py fetch_vault_secret cannot be verified without Vault instance"
        }
    ]
}